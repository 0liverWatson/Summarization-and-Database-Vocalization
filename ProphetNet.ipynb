{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blurr\n",
    "import fastai\n",
    "\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from fastai.text.all import *\n",
    "from transformers import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = datasets.load_dataset('reddit_tifu', 'long', split='train') \n",
    "df = pd.DataFrame(raw_data)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'] = df.apply(lambda row: str(row.tname) + \" [X_SEP] \" + str(row.qType) + \" [X_SEP] \" + str(row.col) + \" [X_SEP] \" + \n",
    "                   str(row.row) + \" [X_SEP] \" + str(row.data) + \" [X_SEP] \" + str(row.stat) + \" [X_SEP] \" , axis = 1)\n",
    "\n",
    "\n",
    "df = df.drop(['tname', 'qType','col','row','data','stat'], axis=1)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice=\"prophetnet\"\n",
    "\n",
    "\"\"\"\n",
    "Working models: \n",
    "- Bert works.. it comes already trained for summarization and we add on that...\n",
    "- Bart works.. (but this might not be RXF), similarly, it seems to be already trained for summarization, so we might just add on that\n",
    "- t5 apparently working, but it seems to be already trained for summarization, so we might just add on that\n",
    "- pegasus working, but it seems it is precisely trained for summarization, so we might just add on that\n",
    "- blenderbot seems to be working and results in something like a summarizer with a strong personality, with a lot of extractive behavior\n",
    "- prophetnet seems to be working after some adaptation... overall good results\n",
    "\"\"\"\n",
    "\n",
    "if model_choice==\"t5\":\n",
    "  pretrained_model_name = \"t5-base\"\n",
    "  m_cls= T5ForConditionalGeneration\n",
    "elif model_choice==\"bert\":\n",
    "  pretrained_model_name = \"patrickvonplaten/bert2bert_cnn_daily_mail\" #\"this is the only model we have that really is structured as an encoder_decoder in HF\n",
    "  m_cls=EncoderDecoderModel\n",
    "elif model_choice==\"pegasus\":  \n",
    "  pretrained_model_name = \"google/pegasus-large\" #large pegasus really uses a lot of RAM :(\n",
    "  m_cls=PegasusForConditionalGeneration\n",
    "elif model_choice==\"bart\": \n",
    "  pretrained_model_name = \"facebook/bart-base\"\n",
    "  m_cls=BartForConditionalGeneration\n",
    "elif model_choice==\"prophetnet\":\n",
    "  pretrained_model_name = \"microsoft/prophetnet-large-uncased-cnndm\"\n",
    "  m_cls=ProphetNetForConditionalGeneration\n",
    "elif model_choice==\"blenderbot\":\n",
    "  pretrained_model_name = \"facebook/blenderbot-90M\"\n",
    "  m_cls=BlenderbotForConditionalGeneration\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, model_cls=m_cls)\n",
    "if model_choice==\"blenderbot\":#we benefit from the similar code structure in Hugging Face\n",
    "  hf_arch=\"bart\"\n",
    "if model_choice==\"bert\":\n",
    "  hf_arch=\"bert_encoder_decoder\"\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task='summarization'); \n",
    "\n",
    "if model_choice==\"t5\" and \"prefix\" in text_gen_kwargs :\n",
    "  del text_gen_kwargs[\"prefix\"]\n",
    "\n",
    "\n",
    "\n",
    "MAX_LENGTH = 300\n",
    "MIN_LENGTH = 30\n",
    "\n",
    "text_gen_kwargs['max_length'] = MAX_LENGTH\n",
    "text_gen_kwargs['min_length'] = MIN_LENGTH\n",
    "\n",
    "text_gen_kwargs['num_beam_groups'] = 1\n",
    "text_gen_kwargs['num_beams'] = 4\n",
    "text_gen_kwargs['temperature'] = 0.6\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=MAX_LENGTH, min_length=MIN_LENGTH, text_gen_kwargs=text_gen_kwargs)\n",
    "blocks = (HF_Seq2SeqBlock(before_batch_tfm=hf_batch_tfm), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('x'), get_y=ColReader('target'), splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(df[:1000], bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dls.train.items), len(dls.valid.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "seq2seq_metrics = {\n",
    "        'rouge': {\n",
    "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics), CSVLogger]\n",
    "\n",
    "\n",
    "\n",
    "def sum_split(m, arch):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "\n",
    "    if arch in ['bert_encoder_decoder']:\n",
    "        embeds = nn.Sequential(\n",
    "          model.encoder.embeddings.word_embeddings,\n",
    "          model.encoder,\n",
    "          model.decoder.cls.predictions.decoder\n",
    "        )\n",
    "        groups = L(embeds, model.encoder, model.decoder.cls.predictions.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    if arch in ['prophetnet']:\n",
    "        embeds = nn.Sequential(\n",
    "          model.prophetnet.word_embeddings,\n",
    "          model.prophetnet.encoder,\n",
    "          model.prophetnet.decoder,\n",
    "        )\n",
    "        groups = L(embeds, model.prophetnet.encoder, model.prophetnet.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    raise ValueError('Invalid architecture')\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=ranger,\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                cbs=learn_cbs,\n",
    "                splitter=partial(seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "learn.create_opt() \n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(learner=learn, max_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(25, lr_max=3e-3,cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(learner=learn, max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"/vol3/bertpro/models/PN_save.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}